{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "descriptions = df['Description'].tolist()\n",
    "categories = df['Genre'].tolist()\n",
    "names = df['title'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = [\n",
    "\n",
    "  model(**tokenizer(description, return_tensors='pt', truncation=True, padding = True))[0].detach().squeeze()\n",
    "  for description in descriptions\n",
    "]\n",
    "[v.size() for v in vectors]\n",
    "\n",
    "#randam vektoriu vidurkius\n",
    "averaged_vectors = [\n",
    "    torch.mean(vector, dim=0) \n",
    "    for vector in vectors\n",
    "    ]\n",
    "#[v.size() for v in averaged_vectors]\n",
    "\n",
    "#print(averaged_vectors)\n",
    "\n",
    "probs = [t.detach().numpy() for t in averaged_vectors]\n",
    "\n",
    "\n",
    "with open('Vectors_names.pkl', 'wb') as f:\n",
    "    pickle.dump(probs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vectors_of_category = [\n",
    "\n",
    "  model(**tokenizer(category, return_tensors='pt', truncation=True, padding = True))[0].detach().squeeze()\n",
    "  for category in categories\n",
    "]\n",
    "#[v.size() for v in vectors]\n",
    "\n",
    "#randam vektoriu vidurkius\n",
    "averaged_vectors_of_category = [\n",
    "    torch.mean(vector_of_category, dim=0) \n",
    "    for vector_of_category in vectors_of_category\n",
    "    ]\n",
    "#[v.size() for v in averaged_vectors]\n",
    "\n",
    "#print(averaged_vectors)\n",
    "\n",
    "probs_of_category = [t.detach().numpy() for t in averaged_vectors_of_category]\n",
    "\n",
    "with open('Vectors_category.pkl', 'wb') as f:\n",
    "    pickle.dump(probs_of_category, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Game : \n",
      "\n",
      " NBA 2K22: NBA 75th Anniversary Edition XBOX LIVE Key UNITED STATES\n",
      "['NBA 2K22 (PC) Steam Key NORTH AMERICA', 'NBA 2K22 (Xbox Series X|S) Xbox Live Key UNITED STATES', 'NBA 2K23 Michael Jordan Edition (Xbox One/Xbox Series S|X) Key UNITED STATES', 'NBA 2K23 for Xbox One Key GLOBAL']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "name = 'NBA'\n",
    "def games_recommender(name):\n",
    "    with open('Vectors_names.pkl', 'rb') as f:\n",
    "     probs = pickle.load(f)\n",
    "\n",
    "\n",
    "\n",
    "    vector_of_name = model(**tokenizer(name, return_tensors='pt', truncation=True, padding = True))[0].detach().squeeze()\n",
    "\n",
    "    similarity = cosine_similarity(vector_of_name, probs)\n",
    "\n",
    "    games = []\n",
    "    for arr in similarity:\n",
    "      for i, each_val in enumerate(arr):\n",
    "         games.append([names[i],each_val])\n",
    "\n",
    "    final_games = sorted(games, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    for arr in final_games[0:1]:\n",
    "    # print(f'\\nScore : \\n\\n  {arr[1]}')\n",
    "      print(f'\\nGame : \\n\\n {arr[0]}')\n",
    "\n",
    "    arr = np.delete(arr,-1)\n",
    "\n",
    "    arr = ''.join(arr)\n",
    "\n",
    "    with open('Vectors1.pkl', 'rb') as f:\n",
    "     probs1 = pickle.load(f)\n",
    "\n",
    "\n",
    "    similarity2 = cosine_similarity(probs1)\n",
    "\n",
    "    indexes = pd.Series(df2['title'])\n",
    "\n",
    "    similar_games = []\n",
    "    idx = indexes[indexes == arr].index[0]  \n",
    "    similarities = pd.Series(similarity2[idx]).sort_values(ascending = False) \n",
    "    indexes_count = list(similarities.iloc[1:5].index)\n",
    "\n",
    "    for i in indexes_count:  \n",
    "        similar_games.append(list(df2['title'])[i])\n",
    "\n",
    "    return similar_games\n",
    "\n",
    "\n",
    "print(games_recommender(name))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "category : \n",
      "\n",
      " Sport\n",
      "['79.95', '57.99', '54.46', '15.66', '48.78', '11.99', '9.99', '20.10', '9.08', '20.07']\n",
      "average price of games in this category is:\n",
      "32.807€\n",
      "games in this category\n",
      "sport\n",
      "are these:\n",
      "\n",
      "['NHL® 23 X-Factor Edition Xbox One & Xbox Series X|S Key UNITED STATES', 'NHL® 23 Standard Edition Xbox Series X|S Key UNITED STATES', 'Mario Strikers: Battle League (Nintendo Switch) eShop Key UNITED STATES', 'The Evil Within Digital Bundle XBOX LIVE Key UNITED STATES', 'Gotham Knights (PC) Steam Key GLOBAL', 'Resident Evil 3 (Xbox One) Xbox Live Key UNITED STATES', 'GUILTY GEAR (PC) Steam Key GLOBAL', 'Resident Evil Revelations 1 & 2 Bundle XBOX LIVE Key UNITED STATES', 'Warhammer 40,000: Space Marine - Anniversary Edition (PC) Steam Key GLOBAL', 'GRID Legends XBOX LIVE Key UNITED STATES']\n"
     ]
    }
   ],
   "source": [
    "category = 'sport'\n",
    "\n",
    "\n",
    "def get_games_by_category(category):\n",
    "    with open('Vectors_category.pkl', 'rb') as f:\n",
    "     probs = pickle.load(f)\n",
    "\n",
    "    vector_of_category = model(**tokenizer(category, return_tensors='pt', truncation=True, padding = True))[0].detach().squeeze()\n",
    "\n",
    "    similarity_of_category = cosine_similarity(vector_of_category, probs)\n",
    "\n",
    "    categor = []\n",
    "    for arr_of_category in similarity_of_category:\n",
    "      for i, each_val in enumerate(arr_of_category):\n",
    "          categor.append([categories[i],each_val])\n",
    "\n",
    "    final_categor = sorted(categor, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    for arr_of_category in final_categor[0:1]:\n",
    "      print(f'\\ncategory : \\n\\n {arr_of_category[0]}')\n",
    "\n",
    "    arr_of_category = np.delete(arr_of_category,-1)\n",
    "\n",
    "    arr_of_category = ''.join(arr_of_category)\n",
    "\n",
    "    similarity_of_category2 = cosine_similarity(probs)\n",
    "\n",
    "    indexes = pd.Series(df2['Genre'])\n",
    "\n",
    "    similar_games = []\n",
    "    Prices = []\n",
    "    idx = indexes[indexes == arr_of_category].index[0]  \n",
    "    similarities = pd.Series(similarity_of_category2[idx]).sort_values(ascending = False) \n",
    "    indexes_count = list(similarities.iloc[1:11].index)  \n",
    "\n",
    "    for i in indexes_count:  \n",
    "        similar_games.append(list(df2['title'])[i])\n",
    "        #similar_games.append(list(df2['Genre'])[i])\n",
    "        Prices.append(list(df2['Price'])[i])\n",
    "\n",
    "    Price = list(map(lambda x: x.strip('€'), Prices))\n",
    "\n",
    "   \n",
    "\n",
    "    #Price = filter(None, Price)\n",
    "\n",
    "    #print(Price)\n",
    "\n",
    "    foo = [float(i) for i in Price]\n",
    "\n",
    "    avg = statistics.mean(foo)\n",
    "\n",
    "    avg=str(avg)\n",
    "\n",
    "    similar_games = str(similar_games)\n",
    "\n",
    "    \n",
    "\n",
    "    print('average price of games in this category is:\\n' + avg + \"€\")\n",
    "\n",
    "    print('games in this category\\n'+ category + '\\nare these:\\n')\n",
    "\n",
    "    return similar_games\n",
    "\n",
    "print(get_games_by_category(category))\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
